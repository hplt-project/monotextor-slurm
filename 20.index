#!/bin/bash
#SBATCH --job-name=index
#SBATCH --partition="small"
#SBATCH --time=24:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=128
## 3750 mem to go for 512gb nodes
#SBATCH --mem-per-cpu=3750
#SBATCH --output=logs/%x.out

set -euo pipefail
shopt -s failglob
source .env

L=$1
COLL=$2
TMPSFX=tmp_$SLURM_JOB_ID
DIR=$WORKSPACE/$COLL/$L
JSON_FILES=$DIR/scored.*.jsonl.zst
# If it's an array job, do distributed index
if env | grep -q 'SLURM_ARRAY_TASK_ID'; then
    QUERY_FILE=$DIR/queries.$SLURM_ARRAY_TASK_ID.zst
    BAND="-b $((SLURM_ARRAY_TASK_ID-1))"
else
    QUERY_FILE=$DIR/queries.zst
    BAND=""
fi

# Build the index and query
# index only one band per job
RAYON_NUM_THREADS=$SLURM_CPUS_ON_NODE \
mhindex --batch-size 5000 $BAND $JSON_FILES \
| zstd -T64 >$QUERY_FILE.$TMPSFX

mv $QUERY_FILE.$TMPSFX $QUERY_FILE
