#!/bin/bash
#SBATCH --job-name=extract-external
#SBATCH --partition="small"
#SBATCH --time=12:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=64
#SBATCH --mem-per-cpu=1750
#SBATCH --output=logs/%x.out

set -euo pipefail
shopt -s failglob
source .env
module load parallel

L=$1
#INPUT=/scratch/project_465000498/external_contributions/nb/NCC_LTG/data/
#INPUT=/scratch/project_465000498/external_contributions/et
INPUT=/scratch/project_465000498/external_contributions/zh
OUTPUT=$WORKSPACE/external/$L
mkdir -p $OUTPUT

# Read the split output, compress it to temp, then move
compress-batch(){
    local file=$1
    # Remove 0s prefix
    local name=$(echo $file | sed -E "s/\_0+/_/g")

    # compress stdin, write to a temp
    zstd -T$SLURM_CPUS_ON_NODE -10 >$name.jsonl.zst.tmp

    # remove temp suffix
    mv $name.jsonl.zst.tmp $name.jsonl.zst
}
extract-part(){
    # Remove first and last line containing the array brackets
    # rename the 'content' field to 'text'
    file=$1
    zstdcat $file \
    | tail -n +2 \
    | head -n -1 \
    | sed -E 's/\s+\},/\}/' \
    | jq -c 'with_entries(if .key == "content" then .key = "text" else . end)'
}
export -f extract-part
export -f compress-batch

parallel -j$SLURM_CPUS_ON_NODE extract-part {} ::: $INPUT/*json.zst \
| split - \
    --numeric-suffixes=1 -a 8 -C 60G \
    --filter='compress-batch $FILE' \
    $OUTPUT/${L}_
